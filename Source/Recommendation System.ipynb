{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75020d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d189db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TourismRecommender:\n",
    "    def __init__(self):\n",
    "        self.user_item_matrix = None\n",
    "        self.user_similarity_matrix = None\n",
    "        self.item_similarity_matrix = None\n",
    "        self.attraction_features = None\n",
    "        self.content_similarity_matrix = None\n",
    "        self.user_profiles = None\n",
    "        self.attraction_profiles = None\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"\n",
    "        Preprocess the tourism dataset for recommendation system\n",
    "        \"\"\"\n",
    "        print(\"Preprocessing data...\")\n",
    "        \n",
    "        # Create user-item matrix (users as rows, attractions as columns, ratings as values)\n",
    "        self.user_item_matrix = df.pivot_table(\n",
    "            index='UserId', \n",
    "            columns='AttractionId', \n",
    "            values='Rating',\n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        # Create attraction feature dataframe\n",
    "        attraction_data = df.drop_duplicates('AttractionId')[\n",
    "            ['AttractionId', 'AttractionType', 'Continent', 'Region', 'Country']\n",
    "        ]\n",
    "        \n",
    "        # Process attraction features for content-based filtering\n",
    "        self.attraction_features = pd.get_dummies(\n",
    "            attraction_data, \n",
    "            columns=['AttractionType', 'Continent', 'Region', 'Country'],\n",
    "            drop_first=False\n",
    "        )\n",
    "        self.attraction_features.set_index('AttractionId', inplace=True)\n",
    "        \n",
    "        # Calculate visit counts and average ratings for each attraction\n",
    "        attraction_stats = df.groupby('AttractionId').agg({\n",
    "            'UserId': 'count',\n",
    "            'Rating': 'mean'\n",
    "        }).rename(columns={'UserId': 'visit_count'})\n",
    "        \n",
    "        # Merge stats into features\n",
    "        self.attraction_features = self.attraction_features.join(attraction_stats)\n",
    "        \n",
    "        # Fill missing values\n",
    "        self.attraction_features.fillna(0, inplace=True)\n",
    "        \n",
    "        print(f\"Processed data: {self.user_item_matrix.shape[0]} users, {self.user_item_matrix.shape[1]} attractions\")\n",
    "        return self\n",
    "    \n",
    "    def build_collaborative_model(self):\n",
    "        \"\"\"\n",
    "        Build a collaborative filtering model based on user-user similarity\n",
    "        \"\"\"\n",
    "        print(\"Building collaborative filtering model...\")\n",
    "        \n",
    "        # Calculate user similarity matrix\n",
    "        self.user_similarity_matrix = cosine_similarity(self.user_item_matrix)\n",
    "        \n",
    "        # Convert to DataFrame for easier indexing\n",
    "        self.user_similarity_matrix = pd.DataFrame(\n",
    "            self.user_similarity_matrix,\n",
    "            index=self.user_item_matrix.index,\n",
    "            columns=self.user_item_matrix.index\n",
    "        )\n",
    "        \n",
    "        # Calculate item similarity matrix\n",
    "        self.item_similarity_matrix = cosine_similarity(self.user_item_matrix.T)\n",
    "        \n",
    "        # Convert to DataFrame for easier indexing\n",
    "        self.item_similarity_matrix = pd.DataFrame(\n",
    "            self.item_similarity_matrix,\n",
    "            index=self.user_item_matrix.columns,\n",
    "            columns=self.user_item_matrix.columns\n",
    "        )\n",
    "        \n",
    "        print(\"Collaborative model built successfully\")\n",
    "        return self\n",
    "    \n",
    "    def build_content_model(self):\n",
    "        \"\"\"\n",
    "        Build a content-based filtering model based on attraction features\n",
    "        \"\"\"\n",
    "        print(\"Building content-based filtering model...\")\n",
    "        \n",
    "        # Scale numerical features\n",
    "        scaler = MinMaxScaler()\n",
    "        numerical_cols = ['visit_count', 'Rating']\n",
    "        self.attraction_features[numerical_cols] = scaler.fit_transform(self.attraction_features[numerical_cols])\n",
    "        \n",
    "        # Calculate content similarity matrix\n",
    "        self.content_similarity_matrix = cosine_similarity(self.attraction_features)\n",
    "        \n",
    "        # Convert to DataFrame for easier indexing\n",
    "        self.content_similarity_matrix = pd.DataFrame(\n",
    "            self.content_similarity_matrix,\n",
    "            index=self.attraction_features.index,\n",
    "            columns=self.attraction_features.index\n",
    "        )\n",
    "        \n",
    "        print(\"Content-based model built successfully\")\n",
    "        return self\n",
    "    \n",
    "    def build_user_profiles(self, df):\n",
    "        \"\"\"\n",
    "        Build user profiles based on their rating history and demographics\n",
    "        \"\"\"\n",
    "        print(\"Building user profiles...\")\n",
    "        \n",
    "        # Group by user to get their demographic information\n",
    "        user_data = df.groupby('UserId').first()\n",
    "        \n",
    "        # Get user preferences for attraction types\n",
    "        user_preferences = df.groupby(['UserId', 'AttractionType'])['Rating'].mean().unstack(fill_value=0)\n",
    "        \n",
    "        # Get user preferences for regions\n",
    "        user_regions = df.groupby(['UserId', 'Region'])['Rating'].mean().unstack(fill_value=0)\n",
    "        \n",
    "        # Combine into user profiles\n",
    "        self.user_profiles = user_data[['Continent', 'Country', 'user_avg_rating_before']]\n",
    "        self.user_profiles = self.user_profiles.join(user_preferences, how='left')\n",
    "        self.user_profiles = self.user_profiles.join(user_regions, how='left')\n",
    "        \n",
    "        # Fill missing values\n",
    "        self.user_profiles.fillna(0, inplace=True)\n",
    "        \n",
    "        print(f\"Built {len(self.user_profiles)} user profiles\")\n",
    "        return self\n",
    "    \n",
    "    def recommend_collaborative(self, user_id, n_recommendations=5, n_neighbors=10):\n",
    "        \"\"\"\n",
    "        Generate recommendations using user-based collaborative filtering\n",
    "        \"\"\"\n",
    "        # Check if user exists\n",
    "        if user_id not in self.user_similarity_matrix.index:\n",
    "            print(f\"User {user_id} not found in training data\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Get user's rated items\n",
    "        user_ratings = self.user_item_matrix.loc[user_id]\n",
    "        rated_items = user_ratings[user_ratings > 0].index.tolist()\n",
    "        \n",
    "        # Find similar users\n",
    "        similar_users = self.user_similarity_matrix[user_id].sort_values(ascending=False)\n",
    "        similar_users = similar_users.drop(user_id)  # Remove the user itself\n",
    "        similar_users = similar_users.head(n_neighbors)\n",
    "        \n",
    "        # Get recommendations from similar users\n",
    "        recommendations = pd.DataFrame(columns=['pred_rating', 'count'])  # Initialize with columns\n",
    "        \n",
    "        for similar_user, similarity in similar_users.items():\n",
    "            # Get items rated by the similar user\n",
    "            similar_user_ratings = self.user_item_matrix.loc[similar_user]\n",
    "            similar_user_rated = similar_user_ratings[similar_user_ratings > 0]\n",
    "            \n",
    "            # Filter out items already rated by the target user\n",
    "            new_attractions = similar_user_rated.drop(rated_items, errors='ignore')\n",
    "            \n",
    "            # Weight ratings by similarity\n",
    "            weighted_ratings = new_attractions * similarity\n",
    "            \n",
    "            # Add to recommendations\n",
    "            for item, rating in weighted_ratings.items():\n",
    "                if item not in recommendations.index:\n",
    "                    recommendations.at[item, 'pred_rating'] = rating\n",
    "                    recommendations.at[item, 'count'] = 1\n",
    "                else:\n",
    "                    recommendations.at[item, 'pred_rating'] += rating\n",
    "                    recommendations.at[item, 'count'] += 1\n",
    "        \n",
    "        # Check if empty before calculating final_rating\n",
    "        if recommendations.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Calculate average predicted rating\n",
    "        recommendations['final_rating'] = recommendations['pred_rating'] / recommendations['count']\n",
    "        \n",
    "        # Sort and return top N recommendations\n",
    "        return recommendations.sort_values('final_rating', ascending=False).head(n_recommendations)\n",
    "    \n",
    "    def recommend_content_based(self, user_id, n_recommendations=5):\n",
    "        \"\"\"\n",
    "        Generate recommendations using content-based filtering\n",
    "        \"\"\"\n",
    "        # Check if user exists\n",
    "        if user_id not in self.user_item_matrix.index:\n",
    "            print(f\"User {user_id} not found in training data\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Get user's rated items\n",
    "        user_ratings = self.user_item_matrix.loc[user_id]\n",
    "        rated_items = user_ratings[user_ratings > 0]\n",
    "        \n",
    "        # Calculate weighted average content similarity\n",
    "        recommendations = pd.DataFrame()\n",
    "        \n",
    "        for item_id in self.attraction_features.index:\n",
    "            # Skip items already rated by the user\n",
    "            if item_id in rated_items.index:\n",
    "                continue\n",
    "            \n",
    "            weighted_sum = 0\n",
    "            similarity_sum = 0\n",
    "            \n",
    "            for rated_item, rating in rated_items.items():\n",
    "                # Get similarity between this item and the rated item\n",
    "                if rated_item in self.content_similarity_matrix.index:\n",
    "                    similarity = self.content_similarity_matrix.loc[item_id, rated_item]\n",
    "                    weighted_sum += similarity * (rating - 3)  # Adjust ratings to be centered around 0\n",
    "                    similarity_sum += abs(similarity)\n",
    "            \n",
    "            if similarity_sum > 0:\n",
    "                # Calculate predicted rating (adjust back to 1-5 scale)\n",
    "                recommendations.at[item_id, 'pred_rating'] = 3 + (weighted_sum / similarity_sum)\n",
    "        \n",
    "        # Sort and return top N recommendations\n",
    "        return recommendations.sort_values('pred_rating', ascending=False).head(n_recommendations)\n",
    "    \n",
    "    def recommend_hybrid(self, user_id, n_recommendations=5, collab_weight=0.7):\n",
    "        \"\"\"\n",
    "        Generate recommendations using a hybrid approach (collaborative + content)\n",
    "        \"\"\"\n",
    "        # Get collaborative filtering recommendations\n",
    "        cf_recs = self.recommend_collaborative(user_id, n_recommendations=10)\n",
    "        \n",
    "        # Get content-based recommendations\n",
    "        cb_recs = self.recommend_content_based(user_id, n_recommendations=10)\n",
    "        \n",
    "        # Combine recommendations with weights\n",
    "        if cf_recs.empty and cb_recs.empty:\n",
    "            return pd.DataFrame()\n",
    "        elif cf_recs.empty:\n",
    "            return cb_recs.head(n_recommendations)\n",
    "        elif cb_recs.empty:\n",
    "            return cf_recs.head(n_recommendations)\n",
    "        \n",
    "        # Normalize ratings to 0-1 scale for fair combination\n",
    "        cf_min = cf_recs['final_rating'].min()\n",
    "        cf_max = cf_recs['final_rating'].max()\n",
    "        if cf_max > cf_min:\n",
    "            cf_recs['norm_rating'] = (cf_recs['final_rating'] - cf_min) / (cf_max - cf_min)\n",
    "        else:\n",
    "            cf_recs['norm_rating'] = 0.5\n",
    "        \n",
    "        cb_min = cb_recs['pred_rating'].min()\n",
    "        cb_max = cb_recs['pred_rating'].max()\n",
    "        if cb_max > cb_min:\n",
    "            cb_recs['norm_rating'] = (cb_recs['pred_rating'] - cb_min) / (cb_max - cb_min)\n",
    "        else:\n",
    "            cb_recs['norm_rating'] = 0.5\n",
    "        \n",
    "        # Combine recommendations\n",
    "        hybrid_recs = pd.DataFrame()\n",
    "        \n",
    "        # Add collaborative filtering recommendations\n",
    "        for item_id, row in cf_recs.iterrows():\n",
    "            hybrid_recs.at[item_id, 'cf_rating'] = row['norm_rating']\n",
    "            hybrid_recs.at[item_id, 'cf_weight'] = collab_weight\n",
    "        \n",
    "        # Add content-based recommendations\n",
    "        for item_id, row in cb_recs.iterrows():\n",
    "            if item_id in hybrid_recs.index:\n",
    "                hybrid_recs.at[item_id, 'cb_rating'] = row['norm_rating']\n",
    "                hybrid_recs.at[item_id, 'cb_weight'] = 1 - collab_weight\n",
    "            else:\n",
    "                hybrid_recs.at[item_id, 'cf_rating'] = 0\n",
    "                hybrid_recs.at[item_id, 'cf_weight'] = collab_weight\n",
    "                hybrid_recs.at[item_id, 'cb_rating'] = row['norm_rating']\n",
    "                hybrid_recs.at[item_id, 'cb_weight'] = 1 - collab_weight\n",
    "        \n",
    "        # Fill missing values\n",
    "        hybrid_recs.fillna(0, inplace=True)\n",
    "        \n",
    "        # Calculate weighted ratings\n",
    "        hybrid_recs['hybrid_rating'] = (\n",
    "            (hybrid_recs['cf_rating'] * hybrid_recs['cf_weight']) + \n",
    "            (hybrid_recs['cb_rating'] * hybrid_recs['cb_weight'])\n",
    "        )\n",
    "        \n",
    "        # Sort and return top N recommendations\n",
    "        return hybrid_recs.sort_values('hybrid_rating', ascending=False).head(n_recommendations)\n",
    "    \n",
    "    def get_attraction_details(self, attraction_ids, attraction_data):\n",
    "        \"\"\"\n",
    "        Get details for recommended attractions\n",
    "        \"\"\"\n",
    "        # Filter attraction data for the recommended IDs\n",
    "        attraction_details = attraction_data[attraction_data['AttractionId'].isin(attraction_ids)]\n",
    "        \n",
    "        # Return relevant columns\n",
    "        return attraction_details[['AttractionId', 'Attraction', 'AttractionType', 'Country', 'Region', 'Rating']]\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"\n",
    "        Save the trained recommendation model\n",
    "        \"\"\"\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "\n",
    "    def load_model(cls, filepath):\n",
    "        \"\"\"\n",
    "        Load a trained recommendation model\n",
    "        \"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        print(f\"Model loaded from {filepath}\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f290850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Processed data: 33530 users, 30 attractions\n",
      "Building collaborative filtering model...\n",
      "Collaborative model built successfully\n",
      "Building content-based filtering model...\n",
      "Content-based model built successfully\n",
      "Building user profiles...\n",
      "Built 33530 user profiles\n",
      "Model saved to C:/Users/Saima Modak/Capstone Projects/Tourism Analysis/Models/Recommendation Model.pkl\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load your tourism data\n",
    "    df = pd.read_excel('C:/Users/Saima Modak/Capstone Projects/Tourism Analysis/Datasets/Final Dataset.xlsx')\n",
    "    \n",
    "    # Initialize and train the recommendation system\n",
    "    recommender = TourismRecommender()\n",
    "    recommender.preprocess_data(df)\n",
    "    recommender.build_collaborative_model()\n",
    "    recommender.build_content_model()\n",
    "    recommender.build_user_profiles(df)\n",
    "    \n",
    "    # Define your desired file path\n",
    "    model_path = \"C:/Users/Saima Modak/Capstone Projects/Tourism Analysis/Models/Recommendation Model.pkl\"\n",
    "    \n",
    "    # Save the model\n",
    "    recommender.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd648029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90524f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d17654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f9052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154efd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041dcb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e74b9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7663cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e58ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410cd58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fb1316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a4bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
